<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>        
    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Marios  Loizou | publications</title>
    <meta name="author" content="Marios  Loizou" />
    <meta name="description" content="Personal webpage
" />
    <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website" />


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous" />

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" />


	<!-- slick carousel -->
	<!-- Add the slick-theme.css if you want default styling -->
	<link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/npm/slick-carousel@1.8.1/slick/slick.css"/>
	<!-- Add the slick-theme.css if you want default styling -->
	<link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/npm/slick-carousel@1.8.1/slick/slick-theme.css"/>

    <!-- Styles -->
    <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ðŸ’»</text></svg>">
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="https://marios2019.github.io/publications/">

    <!-- Dark Mode -->
    <script src="/assets/js/theme.js"></script>
    <script src="/assets/js/dark_mode.js"></script>
  </head>

  <!-- Body -->
  <body class="fixed-top-nav">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="https://marios2019.github.io/"><span class="font-weight-bold">Marios</span>   Loizou</a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item ">
                <a class="nav-link" href="/">about</a>
              </li>
              

              <!-- Other pages -->
              <li class="nav-item active">
                <a class="nav-link" href="/publications/">publications<span class="sr-only">(current)</span></a>
              </li>

              <!-- Toogle theme mode -->
              <div class="toggle-container">
                <a id="light-toggle">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
                </a>
              </div>
            </ul>
          </div>
        </div>
      </nav>
    </header>

    <!-- Content -->
    <div class="container mt-5">
      <!-- page.html -->
        <div class="post">

          <header class="post-header">
            <h1 class="post-title">publications</h1>
            <p class="post-description"></p>
          </header>

          <article>
            <!-- _pages/publications.md -->
<div class="publications">
  <h2 class="year">2024</h2>
  <ol class="bibliography"><li>
<!-- _layouts/bib.html -->

      <div class="row">
        <div class="col-sm-2" style="padding-left: 1.5em">
<img style="box-shadow:4px 4px 8px #000; border-radius:2.5%; width: 100%; max-width: 150px; height: auto" src="../assets/img/facadenet.png">
			<!--">-->
</div>

        <!-- Entry bib key -->
        <div id="Georgiou:2023:FacadeNet" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">FacadeNet: Conditional Facade Synthesis via Selective Editing</div>
          <!-- Author -->
          <div class="author">Georgiou, Y.,Â 
                  <em>Loizou, M.</em>,Â Kelly, T.,Â and Averkiou, M.
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In Proc. WACV</em>, 2024
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://arxiv.org/pdf/2311.01240.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
            <a href="https://github.com/ygeorg01/FacadeNet" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a>
            <a href="https://ygeorg01.github.io/FacadeNet/" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Project Page</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>We introduce FacadeNet, a deep learning approach for synthesizing building 
			   facade images from diverse viewpoints. Our method employs a conditional GAN, taking a
			   single view of a facade along with the desired viewpoint information and 
			   generates an image of the facade from the distinct viewpoint. To 
			   precisely modify view-dependent elements like windows and doors while 
			   preserving the structure of view-independent components such as walls, 
			   we introduce a selective editing module. This module leverages image 
			   embeddings extracted from a pretrained vision transformer. Our 
			   experiments demonstrated state-of-the-art performance on building 
			   facade generation, surpassing alternative methods</p>
          </div>
        </div>
      </div>
</li></ol>

  <h2 class="year">2023</h2>
  <ol class="bibliography">
<li>
<!-- _layouts/bib.html -->

      <div class="row">
        <div class="col-sm-2" style="padding-left: 1.5em">
<img style="box-shadow:4px 4px 8px #000; border-radius:2.5%; width: 100%; max-width: 150px; height: auto" src="../assets/img/CSN.jpeg">
			<!--">-->
</div>

        <!-- Entry bib key -->
        <div id="Loizou:2023:CSN" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Cross-Shape Attention for Part Segmentation of 3D Point Clouds</div>
          <!-- Author -->
          <div class="author">
                  <em>Loizou, M.</em>,Â Garg, S.,Â Petrov, D.,Â Averkiou, M.,Â and Kalogerakis, E.
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>Computer Graphics Forum (Proc. SGP)</em>, 42(5), 2023
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://arxiv.org/pdf/2003.09053.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
            <a href="https://github.com/marios2019/CSN" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a>
            <a href="https://marios2019.github.io/CSN/" class="btn btn-sm z-depth-0" role="button">Project Page</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>We present a deep learning method that propagates point-wise feature representations across shapes within
               a collection for the purpose of 3D shape segmentation. We propose a cross-shape attention mechanism to
               enable interactions between a shapeâ€™s point-wise features and those of other shapes. The mechanism assesses
               both the degree of interaction between points and also mediates feature propagation across shapes, improving
               the accuracy and consistency of the resulting point-wise feature representations for shape segmentation.
               Our method also proposes a shape retrieval measure to select suitable shapes for cross-shape attention
               operations for each test shape. Our experiments demonstrate that our approach yields state-of-the-art
               results in the popular PartNet dataset.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->

      <div class="row">
        <div class="col-sm-2" style="padding-left: 1.5em">
<img style="box-shadow:4px 4px 8px #000; border-radius:2.5%; width: 100%; max-width: 150px; height: auto" src="../assets/img/ANNFASS.png">
			<!--">-->
</div>

        <!-- Entry bib key -->
        <div id="Artopoulos:2023:ANNFASS" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">An artificial neural network framework for classifying the style of cypriot hybrid examples of built heritage in 3D</div>
          <!-- Author -->
          <div class="author">Artopoulos, G.,Â Maslioukova, M. I.,Â Zavou, C.,Â 
                  <em>Loizou, M.</em>,Â Deligiorgi, M.,Â and Averkiou, M.
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>Journal of Cultural Heritage</em>, 63(), 2023
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://www.researchgate.net/profile/Giorgos-Artopoulos/publication/373018277_An_artificial_neural_network_framework_for_classifying_the_style_of_Cypriot_hybrid_examples_of_built_heritage_in_3D/links/64d47feeb684851d3d9b159c/An-artificial-neural-network-framework-for-classifying-the-style-of-Cypriot-hybrid-examples-of-built-heritage-in-3D.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>The article presents a workflow based on Deep Neural Networks (DNNs) and Support Vector Machine (SVM) for identifying 
			   architectural stylistic influences of segmented building parts of Cypriot historical architecture in 3D. The research 
			   contributes in the field of Digital Cultural Heritage (DCH) by applying Machine Learning (ML) and Deep Learning (DL) 
			   on recently published DCH data, with the aim to accelerate the segmentation and annotation process of Historic Building 
			   Information modelling (HBIM) that is currently based on time-consuming manual processes. The method presented works on reality 
			   captured data by 3D documentation techniques, precisely, Terrestrial Laser Scanning (TLS) or Photogrammetry. This workflow was 
			   developed to enable the operation of an online platform,11https://annfass-srv.cs.ucy.ac.cy. which also provides access to the 
			   building data presented here. Ultimately, the results of the presented method are accessible to scholars and students via this 
			   platform which provides multiple functionalities for researchers in the field to use.</p>
          </div>
        </div>
      </div>
</li>
</ol>

  <h2 class="year">2022</h2>
  <ol class="bibliography"><li>
<!-- _layouts/bib.html -->

      <div class="row">
        <div class="col-sm-2" style="padding-left: 1.5em">
<img style="box-shadow:4px 4px 8px #000; border-radius:2.5%; width: 100%; max-width: 150px; height: auto" src="../assets/img/prifit.jpg">
			<!--">-->
</div>

        <!-- Entry bib key -->
        <div id="Sharma:2022:PriFit" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">PRIFIT: Learning to Fit Primitives Improves Few Shot Point Cloud Segmentation</div>
          <!-- Author -->
          <div class="author">Sharma, G.,Â Dash, B.,Â RoyChowdhury, A.,Â Gadelha, M.,Â 
                  <em>Loizou, M.</em>,Â Cao, L.,Â Wang, R,Â Learned-Miller, E. G.,Â Maji, S,Â and Kalogerakis, E.
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In Proc. SGP</em>, 2022
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://arxiv.org/pdf/2112.13942.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
            <a href="https://github.com/Hippogriff/prifit" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a>
            <a href="https://hippogriff.github.io/prifit/" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Project Page</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>We present PriFit, a simple approach for label efficient learning of 3D shape segmentation networks.
	           PriFit is based on a self-supervised task of decomposing the surface of a 3D shape into geometric primitives.
			   It can be readily applied to existing network architectures for 3D shape segmentation, and improves their
			   performance in the few-shot setting, as we demonstrate in the widely used ShapeNet and PartNet benchmarks.
			   PriFit outperforms the prior state-of-the-art in this setting, suggesting that decomposability into primitives
			   is a useful prior for learning representations predictive of semantic parts. We present a number of
			   experiments varying the choice of geometric primitives and downstream tasks to demonstrate the effectiveness
			   of the method.</p>
          </div>
        </div>
      </div>
</li></ol>

  <h2 class="year">2021</h2>
  <ol class="bibliography"><li>
<!-- _layouts/bib.html -->

      <div class="row">
        <div class="col-sm-2" style="padding-left: 1.5em">
<img style="box-shadow:4px 4px 8px #000; border-radius:2.5%; width: 100%; max-width: 150px; height: auto" src="../assets/img/buildingnet.jpg">
			<!--">-->
</div>

        <!-- Entry bib key -->
        <div id="Selvaraju:2021:BuildingNet" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">BuildingNet: Learning to Label 3D Buildings</div>
          <!-- Author -->
          <div class="author">Selvaraju, P.,Â Nabail, M.,Â 
                  <em>Loizou, M.</em>,Â Maslioukova, M.,Â Averkiou, M.,Â Andreou, A.,Â Chaudhuri, S.,Â and Kalogerakis, E.
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In Proc. ICCV</em>, 2021
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://arxiv.org/pdf/2110.04955.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
            <a href="https://github.com/buildingnet/buildingnet_dataset" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a>
            <a href="https://buildingnet.org/" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Project Page</a>
            <a href="https://www.youtube.com/watch?v=rl30WJo_EBo&amp;ab_channel=EvangelosKalogerakis" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Video</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>We introduce BuildingNet: (a) a large-scale dataset of
			   3D building models whose exteriors are consistently labeled,
			   and (b) a graph neural network that labels building meshes
			   by analyzing spatial and structural relations of their geometric
			   primitives. To create our dataset, we used crowdsourcing combined
			   with expert guidance, resulting in 513K annotated mesh primitives,
			   grouped into 292K semantic part components across 2K building models.
			   The dataset covers several building categories, such as houses, 
			   churches, skyscrapers, town halls, libraries, and castles. We include 
			   a benchmark for evaluating mesh and point cloud labeling. Buildings
			   have more challenging structural complexity compared to objects in
			   existing benchmarks (e.g., ShapeNet, PartNet), thus, we hope that 
			   our dataset can nurture the development of algorithms that are able 
			   to cope with such large-scale geometric data for both vision and
			   graphics tasks e.g., 3D semantic segmentation, part-based generative
			   models, correspondences, texturing, and analysis of point cloud data
			   acquired from real-world buildings. Finally, we show that our mesh-based
			   graph neural network significantly improves performance over several
			   baselines for labeling 3D meshes. Our project page www.buildingnet.org
			   includes our dataset and code.</p>
          </div>
        </div>
      </div>
</li></ol>

  <h2 class="year">2020</h2>
  <ol class="bibliography"><li>
<!-- _layouts/bib.html -->

      <div class="row">
        <div class="col-sm-2" style="padding-left: 1.5em">
<img style="box-shadow:4px 4px 8px #000; border-radius:2.5%; width: 100%; max-width: 150px; height: auto" src="../assets/img/pb_dgcnn.jpg">
			<!--">-->
</div>

        <!-- Entry bib key -->
        <div id="Loizou:2021:PB-DGCNN:" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Learning Part Boundaries from 3D Point Clouds</div>
          <!-- Author -->
          <div class="author">
                  <em>Loizou, M.</em>,Â Averkiou, M.,Â and Kalogerakis, E
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>Computer Graphics Forum (Proc. SGP)</em>, 39(5), 2020
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://arxiv.org/pdf/2007.07563.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
            <a href="https://github.com/marios2019/learning_part_boundaries" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a>
            <a href="https://marios2019.github.io/learning_part_boundaries/" class="btn btn-sm z-depth-0" role="button">Project Page</a>
            <a href="https://www.youtube.com/watch?v=pyCZiK28nl0&amp;ab_channel=MariosLoizou" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Video</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>We present a method that detects boundaries of parts in 3D shapes represented as 
			   point clouds. Our method is based on a graph convolutional network architecture that
			   outputs a probability for a point to lie in an area that separates two or more parts
			   in a 3D shape. Our boundary detector is quite generic: it can be trained to localize
			   boundaries of semantic parts or geometric primitives commonly used in 3D modeling.
			   Our experiments demonstrate that our method can extract more accurate boundaries that
			   are closer to ground-truth ones compared to alternatives. We also demonstrate an
			   application of our network to fine-grained semantic shape segmentation, where we also
			   show improvements in terms of part labeling performance.</p>
          </div>
        </div>
      </div>
</li></ol>

  <h2 class="year">2019</h2>
  <ol class="bibliography"><li>
<!-- _layouts/bib.html -->

      <div class="row">
        <div class="col-sm-2" style="padding-left: 1.5em">
<img style="box-shadow:4px 4px 8px #000; border-radius:2.5%; width: 100%; max-width: 150px; height: auto" src="../assets/img/visual_tracking.JPG">
			<!--">-->
</div>

        <!-- Entry bib key -->
        <div id="Loizou:2019:VisualTracking" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Model-Based 3D Visual Tracking of Rigid Bodies using Distance Transform</div>
          <!-- Author -->
          <div class="author">
                  <em>Loizou, M.</em>,Â and Kaimakis, P.
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In Proc. VISUAL</em>, 2019
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://www.researchgate.net/profile/William-Hurst-4/publication/340897785_The_Fourth_International_Conference_on_Applications_and_Systems_of_Visual_Paradigms_-_2019/links/5ea2e33e458515ec3a0306ed/The-Fourth-International-Conference-on-Applications-and-Systems-of-Visual-Paradigms-2019.pdf#page=49" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
            <a href="https://github.com/marios2019/Visual_Tracking" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>The core idea of model-based 3D tracking is that of continuously estimating
			   the pose parameters of a 3D object throughout a sequence of images, e.g., 
			   a video feed. Here, we present an edge-based method for achieving 3D object
			   tracking, via Gauss-Newton optimization. We rely on natural features observations,
			   like edges, for the detection of interest points and by using the 3D pose of the
			   object in the previous frame, we correctly estimate its new 3D position and 
			   orientation, in real-time. There is also a C++ implementation of the visual tracking system,
			   with the use of the OpenCV library, which can be found in our GitHub repository 
			   (https://github.com/marios2019/Visual Tracking).</p>
          </div>
        </div>
      </div>
</li></ol>


</div>

          </article>

        </div>

    </div>

    <!-- Footer -->    
    <footer class="fixed-bottom">
      <div class="container mt-0">
        Â© Copyright 2024 Marios  Loizou. Powered by <a href="http://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="noopener noreferrer">GitHub Pages</a>.

      </div>
    </footer>

    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.11.2/dist/umd/popper.min.js" integrity="sha256-l/1pMF/+J4TThfgARS6KwWrk/egwuVvhRzfLAMQ6Ds4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.min.js" integrity="sha256-SyTu6CwrfOhaznYZPoolVw2rxoY7lKYKQvqbtqN93HI=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Mansory & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/assets/js/mansory.js" type="text/javascript"></script>
    
  <!-- Medium Zoom JS -->
  <script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
  <script src="/assets/js/zoom.js"></script><!-- Load Common JS -->
  <script src="/assets/js/common.js"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-DB0QBNP79R"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());
    gtag('config', 'G-DB0QBNP79R');
  </script>
	<!-- slick -->
  <script type="text/javascript" src="//cdn.jsdelivr.net/npm/slick-carousel@1.8.1/slick/slick.min.js"></script>	

  <script type="text/javascript">
    $(document).ready(function(){
      $('.slide_list').slick({
		 slide: 'li',
		 dots: true,
		 infinite: true,
		 speed: 300,
		 cssEase: 'linear'
      });
    });
  </script>

  </body>
</html>

